import time
import cv2
import torch
import numpy as np
from ultralytics import YOLO


# ì´ë¯¸ì§€ ì¢Œí‘œ (í”½ì…€ ì¢Œí‘œ)
image_points = np.array([
    [335, 102],   
    [23, 251],    
    [584, 234],   
    [146, 404]    
], dtype=np.float32)

# ì‹¤ì œ ì„¸ê³„ ì¢Œí‘œ (ìœ„ë„, ê²½ë„)
world_points = np.array([
    [37.67675942, 126.74583666],  
    [37.67696082, 126.74597894],  
    [37.67687015, 126.74558537],  
    [37.67703350, 126.74581464]   
], dtype=np.float32)

# Homography í–‰ë ¬ ê³„ì‚°
H, status = cv2.findHomography(image_points, world_points)

# ì´ë¯¸ì§€ ì¢Œí‘œë¥¼ ì‹¤ì„¸ê³„ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_image_to_world(image_coords, homography_matrix):
    image_coords_homogeneous = np.array([image_coords[0], image_coords[1], 1]).reshape(3, 1)
    world_coords_homogeneous = np.dot(homography_matrix, image_coords_homogeneous)
    world_coords = world_coords_homogeneous / world_coords_homogeneous[2]
    lat = world_coords[0][0]
    lon = world_coords[1][0]
    return lat, lon



# YOLOv8 ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš© ì„¤ì •)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = YOLO('yolo_version/yolov8n.pt').to(device)

# COCO ë°ì´í„°ì…‹ì—ì„œ ì‚¬ëŒê³¼ ì°¨ëŸ‰ ê´€ë ¨ í´ë˜ìŠ¤ ID
TARGET_CLASSES = [0, 2, 3, 5]  # ì‚¬ëŒ(0), ìë™ì°¨(2), ì˜¤í† ë°”ì´(3), ë²„ìŠ¤(5)

# ì˜ìƒ íŒŒì¼ ê²½ë¡œ
video_path = 'video/ilsan.mp4'
output_path = f"{video_path.rsplit('.', 1)[0]}_output.mp4"

# ì˜ìƒ íŒŒì¼ ì—´ê¸°
cap = cv2.VideoCapture(video_path)

# ì›ë³¸ ì˜ìƒì˜ í”„ë ˆì„, í•´ìƒë„ ê°€ì ¸ì˜¤ê¸°
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# VideoWriter ê°ì²´ ìƒì„±
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

# ì „ì²´ ì‹¤í–‰ ì‹œì‘ ì‹œê°„
start_time = time.time()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # ê°ì²´ ê°ì§€ ìˆ˜í–‰ (ì¶”ì  ëª¨ë“œ)
    results = model.track(frame, classes=TARGET_CLASSES, persist=True)

    # ê°ì§€ëœ ê°ì²´ì˜ ì¢Œí‘œ ì¶”ì 
    for obj in results[0].boxes:
        obj_id = int(obj.id) if obj.id is not None else -1
        bbox = obj.xyxy.cpu().numpy()[0]

        # ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¤‘ì•™ ì¢Œí‘œ ê³„ì‚°
        center_x = int((bbox[0] + bbox[2]) / 2)
        center_y = int((bbox[1] + bbox[3]) / 2)
        
        lat, lon = convert_image_to_world([center_x, center_y], H)
        print(f"ê°ì²´ ID: {obj_id}, ì¢Œí‘œ: ({lat}, {lon})")
        
    # ê°ì§€ëœ ê°ì²´ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°
    frame = results[0].plot()
    
    out.write(frame)
    
    cv2.imshow('YOLOv8 Video Detection', frame)

    # 'q' ì…ë ¥ ì‹œ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ì „ì²´ ì‹¤í–‰ ì¢…ë£Œ ì‹œê°„
end_time = time.time()

cap.release()
out.release()
cv2.destroyAllWindows()

# ì´ ì†Œìš” ì‹œê°„ ì¶œë ¥
total_time = end_time - start_time
print(f"\nğŸ” ì‹¤í–‰ ë””ë°”ì´ìŠ¤: {device.upper()}")
print(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")